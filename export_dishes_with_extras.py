#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–≠–ö–°–ü–û–†–¢ –¢–û–í–ê–†–û–í –° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ú–ò –≠–¢–ò–ö–ï–¢–ö–ê–ú–ò (AddListSauce)
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç: asyncio + aiohttp + –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–ø. —Ç–æ–≤–∞—Ä–æ–≤
"""

import asyncio
import aiohttp
import sqlite3
import json
import time
import signal
import sys
import re
from typing import Dict, List, Any, Optional, Set
from pathlib import Path
from datetime import datetime
import logging

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò
# ============================================================================

# API
SH_URL = "http://10.0.0.141:9797/api/sh5exec"
SH_USER = "Admin"
SH_PASS = "776417"

# –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨
MAX_CONCURRENT = 300        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
REQUEST_TIMEOUT = 30        # –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (—Å–µ–∫)
MAX_RETRIES = 3             # –ü–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
RETRY_DELAYS = [0.5, 1, 2]  # –ó–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

# SQLite
DB_FILE = "dishes_with_extras.sqlite"
BATCH_SIZE = 500            # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è SQLite
PRAGMA_JOURNAL = "WAL"      # Write-Ahead Logging
PRAGMA_SYNC = "NORMAL"      # –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–Ω–∞–¥—ë–∂–Ω–æ—Å—Ç—å
PRAGMA_CACHE = 10000

# –§–ò–õ–¨–¢–†–´
ONLY_WITH_RKEEPER = True
EXCLUDE_SEMIFINISHED = True

# –û–¢–ö–ê–ó–û–£–°–¢–û–ô–ß–ò–í–û–°–¢–¨
MAX_CONSECUTIVE_ERRORS = 100
ERROR_RATE_THRESHOLD = 0.5
ERROR_RATE_PAUSE = 15
ENABLE_ADAPTIVE_THROTTLING = True
MIN_WORKERS = 25

# CHECKPOINT
ENABLE_CHECKPOINT = True
CHECKPOINT_INTERVAL = 1000
CHECKPOINT_FILE = "export_extras_checkpoint.json"

# –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
ERROR_LOG = "export_extras_errors.log"
STATS_LOG = "export_extras_stats.log"

# ============================================================================
# –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï
# ============================================================================

stats = {
    "total": 0,
    "processed": 0,
    "saved": 0,
    "errors": 0,
    "consecutive_errors": 0,
    "skipped": 0,
    "extra_labels_found": 0,
    "extra_labels_processed": 0,
    "cache_hits": 0,
    "cache_misses": 0,
    "start_time": 0,
    "current_workers": MAX_CONCURRENT,
}

processed_rids: Set[int] = set()
shutdown_requested = False

# –ö–µ—à –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –æ–¥–∏–Ω —Å–æ—É—Å 100 —Ä–∞–∑)
extra_dishes_cache: Dict[int, Optional[Dict]] = {}

# ============================================================================
# –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(ERROR_LOG, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def log_error(rid: int, error: str, details: str = ""):
    """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É"""
    with open(ERROR_LOG, 'a', encoding='utf-8') as f:
        f.write(f"[{datetime.now()}] RID={rid} | {error}\n")
        if details:
            f.write(f"  Details: {details}\n")

def log_stats():
    """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    elapsed = time.time() - stats["start_time"]
    speed = stats["processed"] / elapsed if elapsed > 0 else 0

    with open(STATS_LOG, 'a', encoding='utf-8') as f:
        f.write(f"\n[{datetime.now()}] –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n")
        f.write(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}/{stats['total']}\n")
        f.write(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['saved']}\n")
        f.write(f"  –û—à–∏–±–æ–∫: {stats['errors']}\n")
        f.write(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}\n")
        f.write(f"  –î–æ–ø. —ç—Ç–∏–∫–µ—Ç–æ–∫ –Ω–∞–π–¥–µ–Ω–æ: {stats['extra_labels_found']}\n")
        f.write(f"  –î–æ–ø. —ç—Ç–∏–∫–µ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['extra_labels_processed']}\n")
        f.write(f"  Cache hits: {stats['cache_hits']}\n")
        f.write(f"  Cache misses: {stats['cache_misses']}\n")
        f.write(f"  –°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f} —Ç–æ–≤–∞—Ä/—Å–µ–∫\n")
        f.write(f"  –í–æ—Ä–∫–µ—Ä–æ–≤: {stats['current_workers']}\n")

# ============================================================================
# CHECKPOINT –°–ò–°–¢–ï–ú–ê
# ============================================================================

def save_checkpoint():
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å"""
    if not ENABLE_CHECKPOINT:
        return

    checkpoint = {
        "timestamp": datetime.now().isoformat(),
        "processed_rids": list(processed_rids),
        "stats": stats.copy(),
        "cache_size": len(extra_dishes_cache),
    }

    try:
        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, ensure_ascii=False, indent=2)
        logging.info(f"üíæ Checkpoint —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {len(processed_rids)} —Ç–æ–≤–∞—Ä–æ–≤")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è checkpoint: {e}")

def load_checkpoint() -> Optional[Set[int]]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å"""
    if not ENABLE_CHECKPOINT or not Path(CHECKPOINT_FILE).exists():
        return None

    try:
        with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
            checkpoint = json.load(f)

        rids = set(checkpoint.get("processed_rids", []))
        logging.info(f"üìÇ Checkpoint –∑–∞–≥—Ä—É–∂–µ–Ω: {len(rids)} —Ç–æ–≤–∞—Ä–æ–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
        return rids
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ checkpoint: {e}")
        return None

# ============================================================================
# GRACEFUL SHUTDOWN
# ============================================================================

def signal_handler(sig, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏"""
    global shutdown_requested
    logging.info("\n\n‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ...")
    shutdown_requested = True

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ============================================================================
# SQLite
# ============================================================================

def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQLite
    cursor.execute(f"PRAGMA journal_mode = {PRAGMA_JOURNAL}")
    cursor.execute(f"PRAGMA synchronous = {PRAGMA_SYNC}")
    cursor.execute(f"PRAGMA cache_size = {PRAGMA_CACHE}")
    cursor.execute("PRAGMA temp_store = MEMORY")

    # –¢–∞–±–ª–∏—Ü–∞ —Ç–æ–≤–∞—Ä–æ–≤
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS dishes (
            rid INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            rkeeper_code TEXT,
            type INTEGER,
            protein REAL,
            fat REAL,
            carbs REAL,
            calories REAL,
            weight_g REAL,
            calculated_weight_g REAL,
            technology TEXT,
            has_extra_labels INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # –¢–∞–±–ª–∏—Ü–∞ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS ingredients (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            dish_rid INTEGER NOT NULL,
            name TEXT NOT NULL,
            yield_value REAL,
            unit TEXT,
            FOREIGN KEY (dish_rid) REFERENCES dishes(rid)
        )
    """)

    # –ù–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç—Ç–∏–∫–µ—Ç–∫–∏
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS dish_extra_labels (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            main_dish_rid INTEGER NOT NULL,
            extra_dish_rid INTEGER NOT NULL,
            extra_dish_name TEXT NOT NULL,
            extra_dish_rkeeper_code TEXT,
            extra_dish_type INTEGER,
            extra_dish_protein REAL,
            extra_dish_fat REAL,
            extra_dish_carbs REAL,
            extra_dish_calories REAL,
            extra_dish_weight_g REAL,
            extra_dish_calculated_weight_g REAL,
            extra_dish_technology TEXT,
            sort_order INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (main_dish_rid) REFERENCES dishes(rid),
            UNIQUE (main_dish_rid, extra_dish_rid)
        )
    """)

    # –¢–∞–±–ª–∏—Ü–∞ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS extra_dish_ingredients (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            extra_dish_rid INTEGER NOT NULL,
            name TEXT NOT NULL,
            yield_value REAL,
            unit TEXT,
            FOREIGN KEY (extra_dish_rid) REFERENCES dish_extra_labels(extra_dish_rid)
        )
    """)

    conn.commit()
    return conn

def create_indexes(conn: sqlite3.Connection):
    """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã (–≤ –∫–æ–Ω—Ü–µ)"""
    cursor = conn.cursor()
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_rkeeper_code ON dishes(rkeeper_code)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_dish_name ON dishes(name)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_has_extra ON dishes(has_extra_labels)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_ingredients_dish ON ingredients(dish_rid)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_extra_labels_main ON dish_extra_labels(main_dish_rid)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_extra_labels_extra ON dish_extra_labels(extra_dish_rid)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_extra_ingredients ON extra_dish_ingredients(extra_dish_rid)")
    conn.commit()

def save_batch_to_db(conn: sqlite3.Connection, batch: List[Dict]):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞—á–∫—É —Ç–æ–≤–∞—Ä–æ–≤"""
    if not batch:
        return

    cursor = conn.cursor()

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
        dishes_data = [
            (
                d["rid"], d["name"], d["rkeeper_code"], d["type"],
                d["nutrition"]["protein"], d["nutrition"]["fat"],
                d["nutrition"]["carbs"], d["nutrition"]["calories"],
                d["weight_g"], d["calculated_weight_g"], d["technology"],
                1 if d.get("extra_labels") else 0
            )
            for d in batch
        ]

        cursor.executemany("""
            INSERT OR REPLACE INTO dishes
            (rid, name, rkeeper_code, type, protein, fat, carbs, calories,
             weight_g, calculated_weight_g, technology, has_extra_labels)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, dishes_data)

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã
        rids = [d["rid"] for d in batch]
        placeholders = ','.join('?' * len(rids))
        cursor.execute(f"DELETE FROM ingredients WHERE dish_rid IN ({placeholders})", rids)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–ª—é–¥
        all_ingredients = []
        for d in batch:
            for ing in d["ingredients"]:
                all_ingredients.append((
                    d["rid"], ing["name"], ing["yield"], ing["unit"]
                ))

        if all_ingredients:
            cursor.executemany("""
                INSERT INTO ingredients (dish_rid, name, yield_value, unit)
                VALUES (?, ?, ?, ?)
            """, all_ingredients)

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç—Ç–∏–∫–µ—Ç–∫–∏
        cursor.execute(f"DELETE FROM dish_extra_labels WHERE main_dish_rid IN ({placeholders})", rids)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç—Ç–∏–∫–µ—Ç–∫–∏
        all_extra_labels = []
        for d in batch:
            for idx, extra in enumerate(d.get("extra_labels", [])):
                all_extra_labels.append((
                    d["rid"], extra["rid"], extra["name"], extra.get("rkeeper_code"),
                    extra.get("type"), extra["nutrition"]["protein"], extra["nutrition"]["fat"],
                    extra["nutrition"]["carbs"], extra["nutrition"]["calories"],
                    extra["weight_g"], extra["calculated_weight_g"],
                    extra.get("technology"), idx
                ))

        if all_extra_labels:
            cursor.executemany("""
                INSERT INTO dish_extra_labels
                (main_dish_rid, extra_dish_rid, extra_dish_name, extra_dish_rkeeper_code,
                 extra_dish_type, extra_dish_protein, extra_dish_fat, extra_dish_carbs,
                 extra_dish_calories, extra_dish_weight_g, extra_dish_calculated_weight_g,
                 extra_dish_technology, sort_order)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, all_extra_labels)

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        extra_rids = [extra["rid"] for d in batch for extra in d.get("extra_labels", [])]
        if extra_rids:
            placeholders_extra = ','.join('?' * len(extra_rids))
            cursor.execute(f"DELETE FROM extra_dish_ingredients WHERE extra_dish_rid IN ({placeholders_extra})", extra_rids)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
            all_extra_ingredients = []
            for d in batch:
                for extra in d.get("extra_labels", []):
                    for ing in extra.get("ingredients", []):
                        all_extra_ingredients.append((
                            extra["rid"], ing["name"], ing["yield"], ing["unit"]
                        ))

            if all_extra_ingredients:
                cursor.executemany("""
                    INSERT INTO extra_dish_ingredients (extra_dish_rid, name, yield_value, unit)
                    VALUES (?, ?, ?, ?)
                """, all_extra_ingredients)

        conn.commit()
        stats["saved"] += len(batch)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞—Ç—á–∞: {e}")
        conn.rollback()
        raise

# ============================================================================
# API –§–£–ù–ö–¶–ò–ò
# ============================================================================

async def call_procedure(session: aiohttp.ClientSession, proc_name: str,
                        inputs: List[Dict], retry: int = 0) -> Optional[Dict]:
    """–í—ã–∑–æ–≤ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã SH5 —Å retry"""
    payload = {
        "UserName": SH_USER,
        "Password": SH_PASS,
        "procName": proc_name
    }
    if inputs:
        payload["Input"] = inputs

    try:
        async with session.post(
            SH_URL,
            json=payload,
            timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
        ) as resp:
            if resp.status != 200:
                raise Exception(f"HTTP {resp.status}")

            data = await resp.json()

            if data.get("errorCode") != 0:
                raise Exception(f"SH5 error: {data.get('errMessage')}")

            return data

    except asyncio.TimeoutError:
        if retry < MAX_RETRIES:
            await asyncio.sleep(RETRY_DELAYS[retry])
            return await call_procedure(session, proc_name, inputs, retry + 1)
        raise Exception("Timeout after retries")

    except Exception as e:
        if retry < MAX_RETRIES:
            await asyncio.sleep(RETRY_DELAYS[retry])
            return await call_procedure(session, proc_name, inputs, retry + 1)
        raise

def parse_table(table: Dict) -> List[Dict]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Å—Ç—Ä–æ–∫–∏"""
    fields = table.get("fields", [])
    cols = table.get("values", [])
    rec_count = table.get("recCount", 0)

    if not fields or not cols or rec_count <= 0:
        return []

    rows = []
    for i in range(rec_count):
        row = {}
        for j, field in enumerate(fields):
            if j < len(cols) and i < len(cols[j]):
                row[field] = cols[j][i]
        rows.append(row)
    return rows

def find_table(data: Dict, head: str) -> Optional[Dict]:
    """–ù–∞–π—Ç–∏ —Ç–∞–±–ª–∏—Ü—É –ø–æ head"""
    for t in data.get("shTable", []):
        if t.get("head") == head:
            return t
    return None

async def get_goods_tree(session: aiohttp.ClientSession) -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —á–µ—Ä–µ–∑ GoodsTree"""
    logging.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ (GoodsTree)...")

    data = await call_procedure(session, "GoodsTree", [
        {"head": "209", "original": ["1"], "values": [[1]]}
    ])

    t210 = find_table(data, "210")
    if not t210:
        raise RuntimeError("–¢–∞–±–ª–∏—Ü–∞ 210 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    goods = parse_table(t210)
    logging.info(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(goods)}")

    return goods

async def get_dish_details(session: aiohttp.ClientSession, rid: int) -> Dict:
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Ç–æ–≤–∞—Ä–∞ (GoodsItem)"""
    data = await call_procedure(session, "GoodsItem", [
        {"head": "210", "original": ["1"], "values": [[rid]]}
    ])

    t210 = find_table(data, "210")
    if not t210:
        return {}

    rows = parse_table(t210)
    if not rows:
        return {}

    row = rows[0]
    return {
        "protein": row.get("20"),
        "fat": row.get("21"),
        "carbs": row.get("22"),
        "calories": row.get("67"),
        "output": row.get("6\\DishOutput"),
        "technology": row.get("6\\–°ompound") or row.get("6\\Compound"),
        "add_list_sauce": row.get("6\\AddListSauce"),  # –ù–û–í–û–ï –ü–û–õ–ï!
    }

async def get_dish_composition(session: aiohttp.ClientSession, rid: int) -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–∞–≤ —Ç–æ–≤–∞—Ä–∞ (GoodsItemCompDetail)"""
    current_date = datetime.now().strftime("%Y-%m-%d")
    data = await call_procedure(session, "GoodsItemCompDetail", [
        {
            "head": "210#1",
            "original": ["1", "106\\1", "110\\31"],
            "values": [[rid], [None], [current_date]]
        }
    ])

    t218 = find_table(data, "218")
    if not t218:
        return []

    return parse_table(t218)

def calculate_weight(composition: List[Dict]) -> float:
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Å –∏–∑ —Å–æ—Å—Ç–∞–≤–∞"""
    total_grams = 0.0

    for ing in composition:
        parent = ing.get("218#3\\1")
        if parent is not None:
            continue

        yield_value = ing.get("53") or 0
        unit = ing.get("210\\206\\3", "")

        if not yield_value:
            continue

        try:
            yield_float = float(str(yield_value).replace(",", "."))
        except (ValueError, TypeError):
            continue

        unit_lower = unit.strip().lower()
        if unit_lower.startswith("–∫–≥") or unit_lower.startswith("kg"):
            total_grams += yield_float * 1000
        elif unit_lower.startswith("–ª–∏—Ç—Ä") or unit_lower.startswith("l"):
            total_grams += yield_float * 1000
        else:
            total_grams += yield_float

    return total_grams

def parse_add_list_sauce(value: Any) -> List[int]:
    """
    –ü–∞—Ä—Å–∏—Ç—å –ø–æ–ª–µ AddListSauce –≤ —Å–ø–∏—Å–æ–∫ RID'–æ–≤
    –§–æ—Ä–º–∞—Ç: "123, 456, 789" –∏–ª–∏ "123,456,789" –∏–ª–∏ "123" –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    if not value:
        return []

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
    value_str = str(value).strip()
    if not value_str:
        return []

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π
    parts = value_str.split(',')

    rids = []
    for part in parts:
        part = part.strip()
        if part:
            try:
                rid = int(part)
                if rid > 0:
                    rids.append(rid)
            except ValueError:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å RID: '{part}' –≤ AddListSauce")
                continue

    return rids

# ============================================================================
# –û–ë–†–ê–ë–û–¢–ö–ê –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–• –¢–û–í–ê–†–û–í (–° –ö–ï–®–ò–†–û–í–ê–ù–ò–ï–ú)
# ============================================================================

async def fetch_extra_dish(session: aiohttp.ClientSession, rid: int) -> Optional[Dict]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º —Ç–æ–≤–∞—Ä–µ
    –° –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º - –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –≤–µ—Ä–Ω—É—Ç—å –∏–∑ –∫–µ—à–∞
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
    if rid in extra_dishes_cache:
        stats["cache_hits"] += 1
        return extra_dishes_cache[rid]

    stats["cache_misses"] += 1

    try:
        # –ó–∞–ø—Ä–æ—Å 1: GoodsItem (–¥–µ—Ç–∞–ª–∏)
        details = await get_dish_details(session, rid)

        # –ó–∞–ø—Ä–æ—Å 2: GoodsItemCompDetail (—Å–æ—Å—Ç–∞–≤)
        composition = await get_dish_composition(session, rid)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å
        calc_weight = calculate_weight(composition)

        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã
        ingredients = []
        for ing in composition:
            if ing.get("218#3\\1") is not None:
                continue

            yield_val = ing.get("53", 0)
            try:
                yield_float = float(str(yield_val).replace(",", "."))
                if yield_float <= 0:
                    continue
            except (ValueError, TypeError):
                continue

            ing_name = ing.get("210\\3", "")
            ing_name = re.sub(r'^–ü–§\s+\d+\s+', '', ing_name)

            ingredients.append({
                "name": ing_name,
                "yield": yield_float,
                "unit": ing.get("210\\206\\3"),
            })

        result = {
            "rid": rid,
            "name": details.get("name", f"Extra dish {rid}"),
            "rkeeper_code": None,  # –£ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –æ–±—ã—á–Ω–æ –Ω–µ—Ç RK –∫–æ–¥–∞
            "type": None,
            "nutrition": {
                "protein": details.get("protein"),
                "fat": details.get("fat"),
                "carbs": details.get("carbs"),
                "calories": details.get("calories"),
            },
            "weight_g": details.get("output") or calc_weight,
            "calculated_weight_g": calc_weight,
            "ingredients": ingredients,
            "technology": details.get("technology"),
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
        extra_dishes_cache[rid] = result
        stats["extra_labels_processed"] += 1

        return result

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ RID={rid}: {e}")
        extra_dishes_cache[rid] = None  # –ö–µ—à–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á—É —á—Ç–æ–±—ã –Ω–µ –ø—ã—Ç–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞
        return None

# ============================================================================
# –û–ë–†–ê–ë–û–¢–ö–ê –¢–û–í–ê–†–ê
# ============================================================================

async def process_dish(session: aiohttp.ClientSession, goods_item: Dict,
                      semaphore: asyncio.Semaphore) -> Optional[Dict]:
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä"""
    async with semaphore:
        if shutdown_requested:
            return None

        rid = goods_item.get("1")
        name = goods_item.get("3", "")
        rkeeper_code = goods_item.get("241")
        goods_type = goods_item.get("25")

        try:
            # –ó–∞–ø—Ä–æ—Å 1: GoodsItem (–¥–µ—Ç–∞–ª–∏)
            details = await get_dish_details(session, rid)

            # –ó–∞–ø—Ä–æ—Å 2: GoodsItemCompDetail (—Å–æ—Å—Ç–∞–≤)
            composition = await get_dish_composition(session, rid)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å
            calc_weight = calculate_weight(composition)

            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã
            ingredients = []
            for ing in composition:
                if ing.get("218#3\\1") is not None:
                    continue

                yield_val = ing.get("53", 0)
                try:
                    yield_float = float(str(yield_val).replace(",", "."))
                    if yield_float <= 0:
                        continue
                except (ValueError, TypeError):
                    continue

                ing_name = ing.get("210\\3", "")
                ing_name = re.sub(r'^–ü–§\s+\d+\s+', '', ing_name)

                ingredients.append({
                    "name": ing_name,
                    "yield": yield_float,
                    "unit": ing.get("210\\206\\3"),
                })

            # –ù–û–í–û–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç—Ç–∏–∫–µ—Ç–æ–∫
            extra_labels = []
            add_list_sauce = details.get("add_list_sauce")

            if add_list_sauce:
                extra_rids = parse_add_list_sauce(add_list_sauce)

                if extra_rids:
                    stats["extra_labels_found"] += len(extra_rids)
                    logging.debug(f"RID={rid} ({name}): –Ω–∞–π–¥–µ–Ω–æ {len(extra_rids)} –¥–æ–ø. —ç—Ç–∏–∫–µ—Ç–æ–∫: {extra_rids}")

                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –∫–∞–∂–¥–æ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º —Ç–æ–≤–∞—Ä–µ
                    for extra_rid in extra_rids:
                        extra_data = await fetch_extra_dish(session, extra_rid)
                        if extra_data:
                            extra_labels.append(extra_data)

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫
            stats["consecutive_errors"] = 0

            return {
                "rid": rid,
                "name": name,
                "rkeeper_code": rkeeper_code,
                "type": goods_type,
                "nutrition": {
                    "protein": details.get("protein"),
                    "fat": details.get("fat"),
                    "carbs": details.get("carbs"),
                    "calories": details.get("calories"),
                },
                "weight_g": details.get("output") or calc_weight,
                "calculated_weight_g": calc_weight,
                "ingredients": ingredients,
                "technology": details.get("technology"),
                "extra_labels": extra_labels,  # –ù–û–í–û–ï!
            }

        except Exception as e:
            stats["errors"] += 1
            stats["consecutive_errors"] += 1
            log_error(rid, str(e), f"Name: {name}")
            return None

# ============================================================================
# –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –†–ï–ì–£–õ–ò–†–û–í–ö–ê
# ============================================================================

def check_and_adjust_workers(semaphore: asyncio.Semaphore):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å error rate –∏ –æ—Ç—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É"""
    if not ENABLE_ADAPTIVE_THROTTLING:
        return False

    total = stats["processed"]
    if total < 100:
        return False

    error_rate = stats["errors"] / total

    if error_rate > ERROR_RATE_THRESHOLD:
        new_workers = max(MIN_WORKERS, stats["current_workers"] // 2)
        if new_workers != stats["current_workers"]:
            stats["current_workers"] = new_workers
            logging.warning(f"‚ö†Ô∏è  High error rate ({error_rate:.1%}). –°–Ω–∏–∂–∞–µ–º –¥–æ {new_workers} –≤–æ—Ä–∫–µ—Ä–æ–≤")
            return True

    elif error_rate < 0.1 and stats["current_workers"] < MAX_CONCURRENT:
        new_workers = min(MAX_CONCURRENT, stats["current_workers"] + 10)
        stats["current_workers"] = new_workers
        logging.info(f"‚úì Error rate –Ω–∏–∑–∫–∏–π. –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ {new_workers} –≤–æ—Ä–∫–µ—Ä–æ–≤")

    return False

# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    global shutdown_requested

    setup_logging()

    print("="*70)
    print("   –≠–ö–°–ü–û–†–¢ –¢–û–í–ê–†–û–í –° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ú–ò –≠–¢–ò–ö–ï–¢–ö–ê–ú–ò (AddListSauce)")
    print("="*70)
    print(f"\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∏:")
    print(f"  –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {MAX_CONCURRENT}")
    print(f"  –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ SQLite: {BATCH_SIZE}")
    print(f"  –¢–∞–π–º–∞—É—Ç: {REQUEST_TIMEOUT}—Å")
    print(f"  –ü–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ: {MAX_RETRIES}")
    print(f"  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {DB_FILE}")
    print(f"  –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–ø. —Ç–æ–≤–∞—Ä–æ–≤: –î–ê")

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å checkpoint –µ—Å–ª–∏ –µ—Å—Ç—å
    checkpoint_rids = load_checkpoint()
    if checkpoint_rids:
        processed_rids.update(checkpoint_rids)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    conn = init_database()

    # –°–æ–∑–¥–∞—ë–º connector —Å –ø—É–ª–æ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    connector = aiohttp.TCPConnector(
        limit=MAX_CONCURRENT,
        limit_per_host=50,
        ttl_dns_cache=300,
        keepalive_timeout=60
    )

    timeout = aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ–≤–∞—Ä—ã
        all_goods = await get_goods_tree(session)

        # –§–∏–ª—å—Ç—Ä—É–µ–º
        filtered_goods = []
        for g in all_goods:
            rid = g.get("1")

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            if rid in processed_rids:
                continue

            name = str(g.get("3", ""))
            rkeeper_code = g.get("241")

            if ONLY_WITH_RKEEPER and not rkeeper_code:
                continue

            if EXCLUDE_SEMIFINISHED and name.startswith("–ü–§ "):
                continue

            filtered_goods.append(g)

        stats["total"] = len(filtered_goods)
        stats["start_time"] = time.time()

        print(f"\nüìä –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {stats['total']} —Ç–æ–≤–∞—Ä–æ–≤")
        print(f"  –° –∫–æ–¥–æ–º RKeeper: {ONLY_WITH_RKEEPER}")
        print(f"  –ë–µ–∑ –ø–æ–ª—É—Ñ–∞–±—Ä–∏–∫–∞—Ç–æ–≤: {EXCLUDE_SEMIFINISHED}")

        if checkpoint_rids:
            print(f"  –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(checkpoint_rids)} (–ø—Ä–æ–ø—É—â–µ–Ω–æ)")

        print(f"\n{'='*70}")
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        print(f"{'='*70}\n")

        # –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        semaphore = asyncio.Semaphore(stats["current_workers"])

        # –ë–∞—Ç—á –¥–ª—è SQLite
        batch = []

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏
        tasks = [process_dish(session, item, semaphore) for item in filtered_goods]

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        for i, coro in enumerate(asyncio.as_completed(tasks), 1):
            if shutdown_requested:
                logging.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...")
                break

            result = await coro

            stats["processed"] += 1

            if result:
                batch.append(result)
                processed_rids.add(result["rid"])
            else:
                stats["skipped"] += 1

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            elapsed = time.time() - stats["start_time"]
            speed = stats["processed"] / elapsed if elapsed > 0 else 0
            remaining = (stats["total"] - stats["processed"]) / speed if speed > 0 else 0
            progress = stats["processed"] / stats["total"] * 100

            bar_length = 30
            filled = int(bar_length * stats["processed"] / stats["total"])
            bar = "‚ñà" * filled + "‚ñë" * (bar_length - filled)

            print(f"\r[{stats['processed']}/{stats['total']}] {bar} {progress:.1f}% | "
                  f"{speed:.1f} —Ç–æ–≤–∞—Ä/—Å–µ–∫ | ETA: {remaining/60:.1f}–º–∏–Ω | "
                  f"–û—à–∏–±–æ–∫: {stats['errors']} | –î–æ–ø.—ç—Ç–∏–∫–µ—Ç–æ–∫: {stats['extra_labels_found']} | "
                  f"Cache: {stats['cache_hits']}/{stats['cache_hits']+stats['cache_misses']}",
                  end="", flush=True)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á
            if len(batch) >= BATCH_SIZE:
                save_batch_to_db(conn, batch)
                batch = []

            # Checkpoint
            if ENABLE_CHECKPOINT and stats["processed"] % CHECKPOINT_INTERVAL == 0:
                save_checkpoint()
                log_stats()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ error rate
            if stats["processed"] % 100 == 0:
                needs_pause = check_and_adjust_workers(semaphore)
                if needs_pause:
                    logging.warning(f"‚è∏Ô∏è  –ü–∞—É–∑–∞ {ERROR_RATE_PAUSE}—Å –∏–∑-–∑–∞ –≤—ã—Å–æ–∫–æ–≥–æ error rate...")
                    await asyncio.sleep(ERROR_RATE_PAUSE)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ consecutive errors
            if stats["consecutive_errors"] >= MAX_CONSECUTIVE_ERRORS:
                logging.error(f"\n‚ùå –ö–†–ò–¢–ò–ß–ù–û: {MAX_CONSECUTIVE_ERRORS}+ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                break

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞—Ç–∫–∏
        if batch:
            save_batch_to_db(conn, batch)

        # –§–∏–Ω–∞–ª—å–Ω—ã–π checkpoint
        save_checkpoint()

    print("\n")

    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã
    print("üìá –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤...")
    create_indexes(conn)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM dishes")
    total_dishes = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM ingredients")
    total_ingredients = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM dishes WHERE rkeeper_code IS NOT NULL")
    dishes_with_rk = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM dishes WHERE has_extra_labels = 1")
    dishes_with_extras = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM dish_extra_labels")
    total_extra_labels = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(DISTINCT extra_dish_rid) FROM dish_extra_labels")
    unique_extra_dishes = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM extra_dish_ingredients")
    total_extra_ingredients = cursor.fetchone()[0]

    conn.close()

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    elapsed_total = time.time() - stats["start_time"]

    print(f"\n{'='*70}")
    print("‚úÖ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù!")
    print(f"{'='*70}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed_total/60:.1f} –º–∏–Ω—É—Ç ({elapsed_total:.0f} —Å–µ–∫—É–Ω–¥)")
    print(f"üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats['saved']/elapsed_total:.1f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫—É–Ω–¥—É")
    print(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['saved']}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {stats['errors']}")
    print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    print(f"\nüè∑Ô∏è  –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç—Ç–∏–∫–µ—Ç–∫–∏:")
    print(f"  –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π: {stats['extra_labels_found']}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {stats['extra_labels_processed']}")
    print(f"  Cache hits: {stats['cache_hits']}")
    print(f"  Cache misses: {stats['cache_misses']}")
    print(f"\nüìÇ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {DB_FILE}")
    print(f"  –¢–æ–≤–∞—Ä–æ–≤: {total_dishes}")
    print(f"  –° –∫–æ–¥–æ–º RKeeper: {dishes_with_rk}")
    print(f"  –° –¥–æ–ø. —ç—Ç–∏–∫–µ—Ç–∫–∞–º–∏: {dishes_with_extras}")
    print(f"  –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤: {total_ingredients}")
    print(f"  –î–æ–ø. —ç—Ç–∏–∫–µ—Ç–æ–∫ (—Å–≤—è–∑–µ–π): {total_extra_labels}")
    print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–ø. —Ç–æ–≤–∞—Ä–æ–≤: {unique_extra_dishes}")
    print(f"  –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ –¥–æ–ø. —Ç–æ–≤–∞—Ä–æ–≤: {total_extra_ingredients}")
    print(f"  –°—Ä–µ–¥–Ω–∏–π —Å–æ—Å—Ç–∞–≤: {total_ingredients/total_dishes:.1f} –∏–Ω–≥—Ä/—Ç–æ–≤–∞—Ä")
    print(f"{'='*70}")

    log_stats()

# ============================================================================
# –ó–ê–ü–£–°–ö
# ============================================================================

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        save_checkpoint()
        print(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}")
    except Exception as e:
        logging.error(f"\n\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        save_checkpoint()
        sys.exit(1)
